---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am a Research Scientist in the TCL AI Lab at [TCL Research, Hong Kong](https://www.linkedin.com/company/tcl-corporate-research-hk-co-ltd/mycompany/)  where I work on Computer Vision, Machine Learning, and Deep Learning. I received my Ph.D. degree in electrical engineering from the [City University of Hong Kong](https://www.cityu.edu.hk/), in 2019. During my Ph.D. study, I worked under the supervision of [Dr.Lai-Man Po](http://www.ee.cityu.edu.hk/~lmpo/) on Face Liveness detection using Deep Learning techniques. Prior to my Ph.D. degree, I worked in NuSyS Lab under the supervision of [Dr. Muhammad Tariq](https://sites.google.com/a/nu.edu.pk/mtariq/home) on Wireless Multimedia Sensor Networks  (WMSN). I also worked as an Algorithm Specialist with [TCL Corporate Research (Hong Kong) co., Limited](http://tclrd.com.hk/) before assuming duties as a Research Scientist at the same center in 2021.

Research Interests
======
Deep Learning and Computer Vision, Federated Learning, Video Understanding, Computational Photography, Audio Understanding

Collaborators
=====
[Nicholas Lane](http://niclane.org/) (Professor in the  Department of Computer Science and Technology at the University of Cambridge) <br>
[JiaJun Shen](https://scholar.google.com/citations?hl=en&user=qckHL1AAAAAJ&view_op=list_works&sortby=pubdate) (Current: Deep Mind) (Previous: Chief AI Scientist at TCL)<br> 
[Pedro Porto Buarque de Gusm√£o](https://portobgusmao.com/) (Cambridge Machine Learning Systems Lab) <br>
[Yan Gao](https://scholar.google.com/citations?hl=en&user=_im5GrcAAAAJ&view_op=list_works&sortby=pubdate) (University of Cambridge) <br>


News 
====== 

1. **[2023]** Our solution got first place award in [EPIC-SOUNDS Audio-Based Interaction Recognition](https://codalab.lisn.upsaclay.fr/competitions/9729#results).
2. **[2023]** A short highlight on using federated learning with self-supervision for video understanding is now available on the [Flower Blogs](https://flower.dev/blog/2023-04-05-federated-learning-with-self-supervision)
3. **[2022]**  Our paper titled [Federated Self-Supervised Learning for Video Understanding](https://arxiv.org/abs/2207.01975) has been accepted in ECCV-2022
4. **[2022]** Video of my short talk on Federated Learning with Self-Supervision at the Flower Summit 2022 is now available on the [Flower YouTube Channel](https://www.youtube.com/watch?v=ZLqst0lVte8&t=212s)
5. **[2022]** A paper is accepted in [L3D-IVU - CVPR2022](href=https://sites.google.com/view/l3d-ivu/)
6. **[2021]** Our paper titled [VCGAN: Video Colorization with Generative Adversarial Networks](https://arxiv.org/pdf/2104.12357.pdf) has been accepted for publication in IEEE Transactions on Multimedia
7. **[2021]** Our book chapter titled Visual Information Processing and Transmission in Wireless Multimedia Sensor Networks: A Deep Learning-Based Practical Approach has been accepted for publication in the upcoming book [Internet of Multimedia Things (IoMT):  Techniques and Applications](https://www.elsevier.com/books/internet-of-multimedia-things-iomt-techniques-and-applications/shukla/978-0-323-85845-8)

Reviewer
======
1. **Journals:** IEEE TCSVT, IEEE Access, ESWA, JVCI, SPIC
2. **Conferences:** IEEE ICET, IEEE INMIC

